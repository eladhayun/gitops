apiVersion: batch/v1
kind: Job
metadata:
  name: email-import
  namespace: ids
  labels:
    app: email-import
    job-type: data-import
spec:
  # Set backoffLimit to avoid infinite retries on failure
  backoffLimit: 3
  # Don't auto-delete - cleanup CronJob will keep only the latest completed job
  # ttlSecondsAfterFinished: 86400
  template:
    metadata:
      labels:
        app: email-import
        job-type: data-import
    spec:
      restartPolicy: Never
      serviceAccountName: email-import-sa
      
      # Init container to download files from Azure Blob Storage
      initContainers:
      - name: download-emails
        image: mcr.microsoft.com/azure-cli:latest
        command:
          - /bin/sh
          - -c
          - |
            set -e
            echo ""
            echo "==========================================="
            echo "  EMAIL DOWNLOAD FROM AZURE BLOB STORAGE"
            echo "==========================================="
            echo "Storage: ${AZURE_STORAGE_ACCOUNT}"
            echo "Container: ${AZURE_CONTAINER_NAME}"
            echo "Started: $(date '+%Y-%m-%d %H:%M:%S')"
            echo ""
            
            # Create download directory
            mkdir -p /emails
            START_TIME=$(date +%s)
            
            echo "Downloading all files..."
            az storage blob download-batch \
              --account-name ${AZURE_STORAGE_ACCOUNT} \
              --account-key ${AZURE_STORAGE_KEY} \
              --source ${AZURE_CONTAINER_NAME} \
              --destination /emails \
              --pattern "*" \
              --output table
            
            # Summary
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            MINUTES=$((DURATION / 60))
            SECONDS=$((DURATION % 60))
            
            echo ""
            echo "==========================================="
            echo "  DOWNLOAD COMPLETE"
            echo "==========================================="
            echo "Finished: $(date '+%Y-%m-%d %H:%M:%S')"
            echo "Duration: ${MINUTES}m ${SECONDS}s"
            
            FINAL_SIZE=$(du -hs /emails 2>/dev/null | cut -f1 || echo "unknown")
            FILE_COUNT=$(find /emails -type f 2>/dev/null | wc -l | tr -d ' ')
            
            echo "Total Size: $FINAL_SIZE"
            echo "File Count: $FILE_COUNT"
            echo "==========================================="
        env:
        - name: AZURE_STORAGE_ACCOUNT
          valueFrom:
            secretKeyRef:
              name: azure-storage-secret
              key: storage-account-name
        - name: AZURE_STORAGE_KEY
          valueFrom:
            secretKeyRef:
              name: azure-storage-secret
              key: storage-account-key
        - name: AZURE_CONTAINER_NAME
          value: "email-imports"
        volumeMounts:
        - name: email-data
          mountPath: /emails
      
      # Main container to import emails into database
      containers:
      - name: import-emails
        image: prodacr1234.azurecr.io/ids-backend:latest
        command:
          - /bin/sh
          - -c
          - |
            set -e
            echo "===== Starting Email Import Process ====="
            
            # Count files
            eml_count=$(find /emails -name "*.eml" -type f | wc -l)
            mbox_count=$(find /emails -name "*.mbox" -type f | wc -l)
            
            echo "Found $eml_count EML files and $mbox_count MBOX files"
            
            # Import EML files
            if [ "$eml_count" -gt 0 ]; then
              echo "===== Importing EML files ====="
              /app/bin/import-emails -eml /emails -embeddings=true
            fi
            
            # Import MBOX files (one by one if multiple exist)
            if [ "$mbox_count" -gt 0 ]; then
              echo "===== Importing MBOX files ====="
              find /emails -name "*.mbox" -type f | while read mbox_file; do
                echo "Processing: $mbox_file"
                /app/bin/import-emails -mbox "$mbox_file" -embeddings=true
              done
            fi
            
            echo "===== Email Import Complete ====="
            echo "Summary:"
            echo "  - EML files processed: $eml_count"
            echo "  - MBOX files processed: $mbox_count"
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: ids-secrets
              key: database-url
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ids-secrets
              key: openai-api-key
        - name: WAIT_FOR_TUNNEL
          value: "false"
        volumeMounts:
        - name: email-data
          mountPath: /emails
        resources:
          requests:
            memory: "1Gi"      # Increased for large file processing
            cpu: "500m"
          limits:
            memory: "4Gi"      # Allows processing very large MBOX files
            cpu: "2000m"
      
      volumes:
      - name: email-data
        emptyDir:
          sizeLimit: 75Gi  # Increased for 70GB+ email imports (uses FREE node ephemeral storage)

